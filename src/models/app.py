# app.py
import io
import json
from typing import Dict, Any

import numpy as np
import pandas as pd
import streamlit as st
import joblib

# =========================
# –ö–æ–Ω—Ñ–∏–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# =========================
st.set_page_config(page_title="Credit Risk Scoring", page_icon="üí≥", layout="wide")
st.title("üí≥ Credit Risk Scoring Demo")
st.caption("–ú–æ–¥–µ–ª—å: RandomForest + –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ (StandardScaler + OneHotEncoder). –ú–µ—Ç–∫–∏: 0=bad, 1=good")

MODEL_PATH = "src/models/rf_model.pkl"

# –ü—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Ç–æ–º –ø–æ—Ä—è–¥–∫–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–∂–∏–¥–∞–ª–∏—Å—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –ø–∞–π–ø–ª–∞–π–Ω–∞
FEATURES = [
    "age",
    "sex",
    "job",
    "housing",
    "saving_accounts",
    "checking_account",
    "credit_amount",
    "duration",
    "purpose",
]

# =========================
# –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ –º—ç–ø–ø–∏–Ω–≥–∞ (RU -> –∑–Ω–∞—á–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è)
# =========================
JOB_MAP = {
    "–ù–µ—Ç —Ä–∞–±–æ—Ç—ã, –Ω–µ—Ç –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏": 0,
    "–ï—Å—Ç—å —Ä–∞–±–æ—Ç–∞, –Ω–µ—Ç –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏": 1,
    "–ï—Å—Ç—å —Ä–∞–±–æ—Ç–∞, –µ—Å—Ç—å –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è": 2,
    "–í—ã—Å—à–∞—è –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è / –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å": 3,
}

HOUSING_MAP = {
    "–õ–∏—á–Ω–æ–µ": "own",
    "–ê—Ä–µ–Ω–¥–∞": "rent",
    "–ë–µ—Å–ø–ª–∞—Ç–Ω–æ–µ –ø—Ä–æ–∂–∏–≤–∞–Ω–∏–µ": "free",
}

SAVING_MAP = {
    "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö": "no_info",
    "–ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å": "little",
    "–£–º–µ—Ä–µ–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å": "moderate",
    "–í—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ": "quite rich",
    "–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å": "rich",
}

CHECKING_MAP = {
    "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö": "no_info",
    "–ù–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å": "little",
    "–£–º–µ—Ä–µ–Ω–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å": "moderate",
    "–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å": "rich",
}

PURPOSE_MAP = {
    "–ê—É–¥–∏–æ-/–í–∏–¥–µ–æ—Ç–µ—Ö–Ω–∏–∫–∞": "radio/TV",
    "–û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ": "education",
    "–ú–µ–±–µ–ª—å/–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ": "furniture/equipment",
    "–ê–≤—Ç–æ–∫—Ä–µ–¥–∏—Ç": "car",
    "–ë–∏–∑–Ω–µ—Å": "business",
    "–†–µ–º–æ–Ω—Ç": "repairs",
    "–ë—ã—Ç–æ–≤–∞—è —Ç–µ—Ö–Ω–∏–∫–∞": "domestic appliances",
    "–û—Ç–¥—ã—Ö/–î—Ä—É–≥–æ–µ...": "vacation/others",
}

SEX_VALUES = ["–ú—É–∂—á–∏–Ω–∞", "–ñ–µ–Ω—â–∏–Ω–∞"]  # –∫–∞–∫ –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å

# =========================
# –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
# =========================
@st.cache_resource
def load_model():
    model = joblib.load(MODEL_PATH)
    return model

model = load_model()

# –£—Ç–æ—á–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –∫–ª–∞—Å—Å–æ–≤ –∏–∑ –º–æ–¥–µ–ª–∏ (–Ω–∞ —Å–ª—É—á–∞–π –æ—Ç–ª–∏—á–∏–π)
CLASSES = np.array(getattr(model, "classes_", [0, 1]))
IDX_BAD = int(np.where(CLASSES == 0)[0][0])   # –∫–ª–∞—Å—Å 0 = bad
IDX_GOOD = int(np.where(CLASSES == 1)[0][0])  # –∫–ª–∞—Å—Å 1 = good

# =========================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# =========================
def ru_to_model_values(row_ru: Dict[str, Any]) -> Dict[str, Any]:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç RU-–ø–æ–¥–ø–∏—Å–∏ –≤ –∑–Ω–∞—á–µ–Ω–∏—è, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –æ–±—É—á–∞–ª–∞—Å—å –º–æ–¥–µ–ª—å."""
    row = dict(row_ru)
    row["job"] = JOB_MAP[row["job"]]
    row["housing"] = HOUSING_MAP[row["housing"]]
    row["saving_accounts"] = SAVING_MAP[row["saving_accounts"]]
    row["checking_account"] = CHECKING_MAP[row["checking_account"]]
    row["purpose"] = PURPOSE_MAP[row["purpose"]]
    # sex —É–∂–µ –≤ –Ω—É–∂–Ω–æ–º –≤–∏–¥–µ
    return row

def coerce_and_order_df(df: pd.DataFrame) -> pd.DataFrame:
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –∏ –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤."""
    missing = [c for c in FEATURES if c not in df.columns]
    if missing:
        raise ValueError(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing}")
    return df[FEATURES]

def predict_with_threshold(df_model: pd.DataFrame, threshold: float = 0.5) -> pd.DataFrame:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç pred (–ø–æ argmax), proba_bad/proba_good, –∞ —Ç–∞–∫–∂–µ pred_thr –ø–æ –∫–∞—Å—Ç–æ–º–Ω–æ–º—É –ø–æ—Ä–æ–≥—É –¥–ª—è 'good'."""
    proba = model.predict_proba(df_model)
    pred = model.predict(df_model)

    proba_bad = proba[:, IDX_BAD]
    proba_good = proba[:, IDX_GOOD]

    # –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø–æ—Ä–æ–≥: –æ—Ç–Ω–æ—Å–∏–º –∫ good (1), –µ—Å–ª–∏ proba_good >= threshold, –∏–Ω–∞—á–µ bad (0)
    pred_thr = (proba_good >= threshold).astype(int)

    out = pd.DataFrame({
        "pred": pred,  # 0/1
        "proba_bad": proba_bad,
        "proba_good": proba_good,
        "pred_thr": pred_thr,
    })
    return out

# =========================
# SIDEBAR
# =========================
with st.sidebar:
    st.header("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã")
    thr = st.slider("–ü–æ—Ä–æ–≥ –¥–ª—è –æ–¥–æ–±—Ä–µ–Ω–∏—è –∫—Ä–µ–¥–∏—Ç–∞ (–∫–ª–∞—Å—Å 1)", min_value=0.0, max_value=1.0, value=0.5, step=0.01)
    st.caption("–ï—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ–¥–æ–±—Ä–µ–Ω–∏—è ‚â• –ø–æ—Ä–æ–≥–∞, —Ä–µ—à–µ–Ω–∏–µ –ø–æ –ø–æ—Ä–æ–≥—É = –û–î–û–ë–†–ò–¢–¨, –∏–Ω–∞—á–µ = –û–¢–ö–õ–û–ù–ò–¢–¨.")
    st.divider()
    st.markdown("**–û–∂–∏–¥–∞–µ–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:**")
    st.code(", ".join(FEATURES), language="text")

# =========================
# –¢–ê–ë–´
# =========================
tab1, tab2 = st.tabs(["üßç Single", "üìÑ Batch CSV"])

# =========================
# TAB 1: Single
# =========================
with tab1:
    st.subheader("–ï–¥–∏–Ω–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")

    col1, col2 = st.columns(2)
    ui_values = {}

    with col1:
        ui_values["age"] = st.number_input("–í–æ–∑—Ä–∞—Å—Ç", min_value=18, max_value=90, value=30)
        ui_values["job"] = st.selectbox(
            "–†–∞–±–æ—Ç–∞/–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è",
            list(JOB_MAP.keys()),
            index=1
        )
        ui_values["credit_amount"] = st.number_input("–°—É–º–º–∞ –∫—Ä–µ–¥–∏—Ç–∞", min_value=100, max_value=200000, value=3000)
        ui_values["duration"] = st.slider("–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–º–µ—Å.)", 4, 72, 24)
        ui_values["sex"] = st.selectbox("–ü–æ–ª", SEX_VALUES, index=0)

    with col2:
        ui_values["housing"] = st.selectbox("–ñ–∏–ª—å—ë", list(HOUSING_MAP.keys()), index=0)
        ui_values["saving_accounts"] = st.selectbox("–°–±–µ—Ä–µ–∂–µ–Ω–∏—è", list(SAVING_MAP.keys()), index=0)
        ui_values["checking_account"] = st.selectbox("–¢–µ–∫—É—â–∏–π —Å—á—ë—Ç", list(CHECKING_MAP.keys()), index=0)
        ui_values["purpose"] = st.selectbox("–¶–µ–ª—å –∫—Ä–µ–¥–∏—Ç–∞", list(PURPOSE_MAP.keys()), index=0)

    if st.button("–ê–ù–ê–õ–ò–ó", use_container_width=True):
        try:
            # RU -> –∑–Ω–∞—á–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
            model_row = ru_to_model_values(ui_values)
            df_in = pd.DataFrame([model_row])
            df_in = coerce_and_order_df(df_in)

            res = predict_with_threshold(df_in, threshold=thr).iloc[0]

            base_pred_text = "–ù–ê–î–Å–ñ–ï–ù (good, –∫–ª–∞—Å—Å 1)" if int(res["pred"]) == 1 else "–ù–ï–ù–ê–î–Å–ñ–ï–ù (bad, –∫–ª–∞—Å—Å 0)"
            thr_pred_text = "–ù–ê–î–Å–ñ–ï–ù (good, –∫–ª–∞—Å—Å 1)" if int(res["pred_thr"]) == 1 else "–ù–ï–ù–ê–î–Å–ñ–ï–ù (bad, –∫–ª–∞—Å—Å 0)"

            st.success(f"–ë–∞–∑–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (argmax): **{base_pred_text}**")
            st.info(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ –ø–æ—Ä–æ–≥—É {thr:.2f}: **{thr_pred_text}**")

            st.markdown("**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–æ–≤:**")
            st.json({
                "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–µ—Ñ–æ–ª—Ç–∞ (bad=0)": float(res["proba_bad"]),
                "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–≥–∞—à–µ–Ω–∏—è (good=1)": float(res["proba_good"]),
            })

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")

# =========================
# TAB 2: Batch CSV
# =========================
with tab2:
    st.subheader("–ü–∞–∫–µ—Ç–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (CSV)")
    st.caption("–û–∂–∏–¥–∞–µ—Ç—Å—è CSV **—Å –∞–Ω–≥–ª. –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏** –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ (sex, housing, saving_accounts, checking_account, purpose). "
               "–ö–æ–ª–æ–Ω–∫–∏: " + ", ".join(FEATURES))

    upl = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV", type=["csv"])
    if upl is not None:
        try:
            df = pd.read_csv(upl)

            df = coerce_and_order_df(df)
            out = predict_with_threshold(df, threshold=thr)

            result = pd.concat([df.reset_index(drop=True), out], axis=1)

            st.write("–†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞:", df.shape, " | –†–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞:", result.shape)
            st.dataframe(result.head(50), use_container_width=True)

            buf = io.BytesIO()
            result.to_csv(buf, index=False)
            st.download_button("‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å predictions.csv", buf.getvalue(),
                               file_name="predictions.csv", mime="text/csv", use_container_width=True)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
